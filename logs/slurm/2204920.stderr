Traceback (most recent call last):
  File "finetune-qa.py", line 85, in <module>
    tokenizer = BertTokenizer.from_pretrained(model_name)
  File "/mnt/home/puxuan/miniconda3/envs/rtx/lib/python3.7/site-packages/transformers/tokenization_utils_base.py", line 1140, in from_pretrained
    return cls._from_pretrained(*inputs, **kwargs)
  File "/mnt/home/puxuan/miniconda3/envs/rtx/lib/python3.7/site-packages/transformers/tokenization_utils_base.py", line 1246, in _from_pretrained
    list(cls.vocab_files_names.values()),
OSError: Model name '/mnt/scratch/puxuan/short_qlm-rr/2147416/huggingface-19' was not found in tokenizers model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). We assumed '/mnt/scratch/puxuan/short_qlm-rr/2147416/huggingface-19' was a path, a model identifier, or url to a directory containing vocabulary files named ['vocab.txt'] but couldn't find such vocabulary files at this path or url.
srun: error: asimov-210: task 0: Exited with exit code 1
