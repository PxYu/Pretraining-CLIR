00:00:07 - Namespace(apex_level='O2', batch_size=8, cased=False, dataset='clef', debug=False, encoder_lr=2e-05, eval_step=1, full_doc_length=True, local_rank=0, model_path='/mnt/scratch/puxuan/long_qlm-rr/2186742/huggingface-3', model_type='mbert-long', num_epochs=20, num_ft_encoders=3, num_neg=1, projector_lr=2e-05, seed=611, source_lang='en', target_lang='de')
00:00:17 - BertLongForXLRetrieval(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(105879, 768, padding_idx=0)
      (position_embeddings): Embedding(1024, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): LongformerSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (query_global): Linear(in_features=768, out_features=768, bias=True)
              (key_global): Linear(in_features=768, out_features=768, bias=True)
              (value_global): Linear(in_features=768, out_features=768, bias=True)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): LongformerSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (query_global): Linear(in_features=768, out_features=768, bias=True)
              (key_global): Linear(in_features=768, out_features=768, bias=True)
              (value_global): Linear(in_features=768, out_features=768, bias=True)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): LongformerSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (query_global): Linear(in_features=768, out_features=768, bias=True)
              (key_global): Linear(in_features=768, out_features=768, bias=True)
              (value_global): Linear(in_features=768, out_features=768, bias=True)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): LongformerSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (query_global): Linear(in_features=768, out_features=768, bias=True)
              (key_global): Linear(in_features=768, out_features=768, bias=True)
              (value_global): Linear(in_features=768, out_features=768, bias=True)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): LongformerSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (query_global): Linear(in_features=768, out_features=768, bias=True)
              (key_global): Linear(in_features=768, out_features=768, bias=True)
              (value_global): Linear(in_features=768, out_features=768, bias=True)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): LongformerSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (query_global): Linear(in_features=768, out_features=768, bias=True)
              (key_global): Linear(in_features=768, out_features=768, bias=True)
              (value_global): Linear(in_features=768, out_features=768, bias=True)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): LongformerSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (query_global): Linear(in_features=768, out_features=768, bias=True)
              (key_global): Linear(in_features=768, out_features=768, bias=True)
              (value_global): Linear(in_features=768, out_features=768, bias=True)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): LongformerSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (query_global): Linear(in_features=768, out_features=768, bias=True)
              (key_global): Linear(in_features=768, out_features=768, bias=True)
              (value_global): Linear(in_features=768, out_features=768, bias=True)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): LongformerSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (query_global): Linear(in_features=768, out_features=768, bias=True)
              (key_global): Linear(in_features=768, out_features=768, bias=True)
              (value_global): Linear(in_features=768, out_features=768, bias=True)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): LongformerSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (query_global): Linear(in_features=768, out_features=768, bias=True)
              (key_global): Linear(in_features=768, out_features=768, bias=True)
              (value_global): Linear(in_features=768, out_features=768, bias=True)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): LongformerSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (query_global): Linear(in_features=768, out_features=768, bias=True)
              (key_global): Linear(in_features=768, out_features=768, bias=True)
              (value_global): Linear(in_features=768, out_features=768, bias=True)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): LongformerSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (query_global): Linear(in_features=768, out_features=768, bias=True)
              (key_global): Linear(in_features=768, out_features=768, bias=True)
              (value_global): Linear(in_features=768, out_features=768, bias=True)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (mlm_cls): BertOnlyMLMHead(
    (predictions): BertLMPredictionHead(
      (transform): BertPredictionHeadTransform(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      )
      (decoder): Linear(in_features=768, out_features=105879, bias=True)
    )
  )
  (seqcls_dropout): Dropout(p=0.1, inplace=False)
  (seqcls_classifier): Linear(in_features=768, out_features=2, bias=True)
)
00:00:17 - Evaluating every 1 epochs ...
00:00:17 - reading data from /mnt/home/puxuan/CLIR-project/Evaluation_data/process-clef/uncased
00:00:18 - test has 38 queries ...
00:00:18 - Data reading done ...
00:00:25 - adding 9-th encoder to optimizer...
00:00:25 - adding 10-th encoder to optimizer...
00:00:25 - adding 11-th encoder to optimizer...
00:00:26 - process[0]: training epoch 0 ...
00:00:54 - process[0] - epoch 0 - train iter 423 - 16056.4 words/s - loss: 0.5847
00:00:54 - process[0]: training epoch 1 ...
00:01:22 - process[0] - epoch 1 - train iter 423 - 16617.1 words/s - loss: 0.4787
00:01:22 - process[0]: training epoch 2 ...
00:01:49 - process[0] - epoch 2 - train iter 423 - 16579.2 words/s - loss: 0.4387
00:01:49 - process[0]: training epoch 3 ...
00:02:17 - process[0] - epoch 3 - train iter 423 - 16652.7 words/s - loss: 0.4741
00:02:17 - process[0]: training epoch 4 ...
00:02:45 - process[0] - epoch 4 - train iter 423 - 16382.2 words/s - loss: 0.4564
00:02:45 - process[0]: training epoch 5 ...
00:03:13 - process[0] - epoch 5 - train iter 423 - 16742.0 words/s - loss: 0.4345
00:03:13 - process[0]: training epoch 6 ...
00:03:41 - process[0] - epoch 6 - train iter 423 - 16687.2 words/s - loss: 0.4038
00:03:41 - process[0]: training epoch 7 ...
00:04:08 - process[0] - epoch 7 - train iter 423 - 16611.8 words/s - loss: 0.3677
00:04:08 - process[0]: training epoch 8 ...
00:04:36 - process[0] - epoch 8 - train iter 423 - 16191.7 words/s - loss: 0.3842
00:04:36 - process[0]: training epoch 9 ...
00:05:06 - process[0] - epoch 9 - train iter 423 - 15345.9 words/s - loss: 0.3877
00:05:06 - process[0]: training epoch 10 ...
00:05:34 - process[0] - epoch 10 - train iter 423 - 16844.5 words/s - loss: 0.3670
00:05:34 - process[0]: evaluating epoch 10 on dev ...
00:06:14 - dev set during evaluation: 13890/13887
00:06:14 - process[0] - dev - epoch 10 - mAP: 0.546 w/ 38 queries
00:06:14 - removing file tmp_5f/mbert-long_ende_dev_2_10.txt
00:06:14 - removing file tmp_5f/mbert-long_ende_dev_5_10.txt
00:06:14 - removing file tmp_5f/mbert-long_ende_dev_8_10.txt
00:06:14 - removing file tmp_5f/mbert-long_ende_dev_7_10.txt
00:06:14 - removing file tmp_5f/mbert-long_ende_dev_6_10.txt
00:06:14 - removing file tmp_5f/mbert-long_ende_dev_9_10.txt
00:06:14 - removing file tmp_5f/mbert-long_ende_dev_0_10.txt
00:06:14 - removing file tmp_5f/mbert-long_ende_dev_4_10.txt
00:06:14 - removing file tmp_5f/mbert-long_ende_dev_3_10.txt
00:06:14 - removing file tmp_5f/mbert-long_ende_dev_1_10.txt
00:06:14 - process[0]: evaluating epoch 10 on test ...
00:06:54 - test set during evaluation: 15580/15574
00:06:54 - process[0] - test - epoch 10 - mAP: 0.534 w/ 38 queries
00:06:54 - removing file tmp_5f/mbert-long_ende_test_7_10.txt
00:06:54 - removing file tmp_5f/mbert-long_ende_test_1_10.txt
00:06:54 - removing file tmp_5f/mbert-long_ende_test_6_10.txt
00:06:54 - removing file tmp_5f/mbert-long_ende_test_5_10.txt
00:06:54 - removing file tmp_5f/mbert-long_ende_test_8_10.txt
00:06:54 - removing file tmp_5f/mbert-long_ende_test_4_10.txt
00:06:54 - removing file tmp_5f/mbert-long_ende_test_0_10.txt
00:06:54 - removing file tmp_5f/mbert-long_ende_test_3_10.txt
00:06:54 - removing file tmp_5f/mbert-long_ende_test_9_10.txt
00:06:54 - removing file tmp_5f/mbert-long_ende_test_2_10.txt
00:06:54 - process[0]: training epoch 11 ...
00:07:20 - process[0] - epoch 11 - train iter 423 - 16906.1 words/s - loss: 0.3596
00:07:20 - process[0]: evaluating epoch 11 on dev ...
00:08:00 - dev set during evaluation: 13890/13887
00:08:00 - process[0] - dev - epoch 11 - mAP: 0.531 w/ 38 queries
00:08:00 - removing file tmp_5f/mbert-long_ende_dev_2_11.txt
00:08:00 - removing file tmp_5f/mbert-long_ende_dev_9_11.txt
00:08:00 - removing file tmp_5f/mbert-long_ende_dev_5_11.txt
00:08:00 - removing file tmp_5f/mbert-long_ende_dev_1_11.txt
00:08:00 - removing file tmp_5f/mbert-long_ende_dev_0_11.txt
00:08:00 - removing file tmp_5f/mbert-long_ende_dev_6_11.txt
00:08:00 - removing file tmp_5f/mbert-long_ende_dev_4_11.txt
00:08:00 - removing file tmp_5f/mbert-long_ende_dev_3_11.txt
00:08:00 - removing file tmp_5f/mbert-long_ende_dev_8_11.txt
00:08:00 - removing file tmp_5f/mbert-long_ende_dev_7_11.txt
00:08:00 - process[0]: training epoch 12 ...
00:08:28 - process[0] - epoch 12 - train iter 423 - 16301.6 words/s - loss: 0.3461
00:08:28 - process[0]: evaluating epoch 12 on dev ...
00:09:07 - dev set during evaluation: 13890/13887
00:09:07 - process[0] - dev - epoch 12 - mAP: 0.534 w/ 38 queries
00:09:07 - removing file tmp_5f/mbert-long_ende_dev_1_12.txt
00:09:07 - removing file tmp_5f/mbert-long_ende_dev_3_12.txt
00:09:07 - removing file tmp_5f/mbert-long_ende_dev_0_12.txt
00:09:07 - removing file tmp_5f/mbert-long_ende_dev_5_12.txt
00:09:07 - removing file tmp_5f/mbert-long_ende_dev_2_12.txt
00:09:07 - removing file tmp_5f/mbert-long_ende_dev_9_12.txt
00:09:07 - removing file tmp_5f/mbert-long_ende_dev_7_12.txt
00:09:07 - removing file tmp_5f/mbert-long_ende_dev_4_12.txt
00:09:07 - removing file tmp_5f/mbert-long_ende_dev_6_12.txt
00:09:07 - removing file tmp_5f/mbert-long_ende_dev_8_12.txt
00:09:07 - process[0]: training epoch 13 ...
00:09:36 - process[0] - epoch 13 - train iter 423 - 15899.9 words/s - loss: 0.3127
00:09:36 - process[0]: evaluating epoch 13 on dev ...
