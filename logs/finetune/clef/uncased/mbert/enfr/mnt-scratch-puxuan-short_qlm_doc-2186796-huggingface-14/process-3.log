00:00:06 - Namespace(apex_level='O2', batch_size=8, cased=False, dataset='clef', debug=False, encoder_lr=2e-05, eval_step=1, full_doc_length=True, local_rank=3, model_path='/mnt/scratch/puxuan/short_qlm_doc/2186796/huggingface-14', model_type='mbert', num_epochs=20, num_ft_encoders=3, num_neg=1, projector_lr=2e-05, seed=611, source_lang='en', target_lang='fr')
00:00:14 - Evaluating every 1 epochs ...
00:00:14 - reading data from /mnt/home/puxuan/CLIR-project/Evaluation_data/process-clef/uncased
00:00:15 - test has 37 queries ...
00:00:15 - Data reading done ...
00:00:21 - adding 9-th encoder to optimizer...
00:00:21 - adding 10-th encoder to optimizer...
00:00:21 - adding 11-th encoder to optimizer...
00:00:22 - process[3]: training epoch 0 ...
00:00:31 - process[3] - epoch 0 - train iter 241 - 20361.0 words/s - loss: 0.6889
00:00:31 - process[3]: training epoch 1 ...
00:00:40 - process[3] - epoch 1 - train iter 241 - 21980.4 words/s - loss: 0.6750
00:00:40 - process[3]: training epoch 2 ...
00:00:49 - process[3] - epoch 2 - train iter 241 - 21170.4 words/s - loss: 0.6467
00:00:49 - process[3]: training epoch 3 ...
00:00:58 - process[3] - epoch 3 - train iter 241 - 22288.7 words/s - loss: 0.6593
00:00:58 - process[3]: training epoch 4 ...
00:01:07 - process[3] - epoch 4 - train iter 241 - 21871.6 words/s - loss: 0.6464
00:01:07 - process[3]: training epoch 5 ...
00:01:16 - process[3] - epoch 5 - train iter 241 - 22105.2 words/s - loss: 0.6480
00:01:16 - process[3]: training epoch 6 ...
00:01:24 - process[3] - epoch 6 - train iter 241 - 22952.9 words/s - loss: 0.6184
00:01:24 - process[3]: training epoch 7 ...
00:01:33 - process[3] - epoch 7 - train iter 241 - 22799.6 words/s - loss: 0.5895
00:01:33 - process[3]: training epoch 8 ...
00:01:41 - process[3] - epoch 8 - train iter 241 - 22214.0 words/s - loss: 0.5254
00:01:41 - process[3]: training epoch 9 ...
00:01:50 - process[3] - epoch 9 - train iter 241 - 22082.6 words/s - loss: 0.5554
00:01:50 - process[3]: training epoch 10 ...
00:01:59 - process[3] - epoch 10 - train iter 241 - 21834.9 words/s - loss: 0.5143
00:01:59 - process[3]: evaluating epoch 10 on dev ...
00:02:22 - process[3] - dev - epoch 10 - mAP: 0.308 w/ 37 queries
00:02:22 - process[3]: evaluating epoch 10 on test ...
00:02:41 - test set during evaluation: 11380/11372
00:02:41 - process[3] - test - epoch 10 - mAP: 0.251 w/ 37 queries
00:02:41 - process[3]: training epoch 11 ...
00:02:50 - process[3] - epoch 11 - train iter 241 - 21939.7 words/s - loss: 0.5190
00:02:50 - process[3]: evaluating epoch 11 on dev ...
00:03:09 - process[3] - dev - epoch 11 - mAP: 0.335 w/ 37 queries
00:03:09 - process[3]: evaluating epoch 11 on test ...
00:03:28 - test set during evaluation: 11380/11372
00:03:28 - process[3] - test - epoch 11 - mAP: 0.297 w/ 37 queries
00:03:28 - process[3]: training epoch 12 ...
00:03:36 - process[3] - epoch 12 - train iter 241 - 22993.3 words/s - loss: 0.5155
00:03:36 - process[3]: evaluating epoch 12 on dev ...
00:03:55 - process[3] - dev - epoch 12 - mAP: 0.355 w/ 37 queries
00:03:55 - process[3]: evaluating epoch 12 on test ...
00:04:14 - test set during evaluation: 11380/11372
00:04:14 - process[3] - test - epoch 12 - mAP: 0.343 w/ 37 queries
00:04:14 - process[3]: training epoch 13 ...
00:04:23 - process[3] - epoch 13 - train iter 241 - 21813.5 words/s - loss: 0.4700
00:04:23 - process[3]: evaluating epoch 13 on dev ...
00:04:43 - process[3] - dev - epoch 13 - mAP: 0.338 w/ 37 queries
00:04:43 - process[3]: training epoch 14 ...
00:04:52 - process[3] - epoch 14 - train iter 241 - 21931.4 words/s - loss: 0.5540
00:04:52 - process[3]: evaluating epoch 14 on dev ...
00:05:11 - process[3] - dev - epoch 14 - mAP: 0.344 w/ 37 queries
00:05:11 - process[3]: training epoch 15 ...
00:05:19 - process[3] - epoch 15 - train iter 241 - 21971.7 words/s - loss: 0.5177
00:05:19 - process[3]: evaluating epoch 15 on dev ...
00:05:38 - process[3] - dev - epoch 15 - mAP: 0.359 w/ 37 queries
00:05:38 - process[3]: evaluating epoch 15 on test ...
00:05:57 - test set during evaluation: 11380/11372
00:05:57 - process[3] - test - epoch 15 - mAP: 0.355 w/ 37 queries
00:05:57 - process[3]: training epoch 16 ...
00:06:06 - process[3] - epoch 16 - train iter 241 - 20950.2 words/s - loss: 0.4967
00:06:06 - process[3]: evaluating epoch 16 on dev ...
00:06:26 - process[3] - dev - epoch 16 - mAP: 0.344 w/ 37 queries
00:06:26 - process[3]: training epoch 17 ...
00:06:35 - process[3] - epoch 17 - train iter 241 - 22049.3 words/s - loss: 0.5019
00:06:35 - process[3]: evaluating epoch 17 on dev ...
00:06:53 - process[3] - dev - epoch 17 - mAP: 0.352 w/ 37 queries
00:06:53 - process[3]: training epoch 18 ...
00:07:02 - process[3] - epoch 18 - train iter 241 - 22307.1 words/s - loss: 0.5217
00:07:02 - process[3]: evaluating epoch 18 on dev ...
00:07:21 - process[3] - dev - epoch 18 - mAP: 0.356 w/ 37 queries
00:07:21 - process[3]: training epoch 19 ...
00:07:29 - process[3] - epoch 19 - train iter 241 - 22924.1 words/s - loss: 0.4697
00:07:29 - process[3]: evaluating epoch 19 on dev ...
00:07:48 - process[3] - dev - epoch 19 - mAP: 0.364 w/ 37 queries
00:07:48 - process[3]: evaluating epoch 19 on test ...
00:08:07 - test set during evaluation: 11380/11372
00:08:07 - process[3] - test - epoch 19 - mAP: 0.369 w/ 37 queries
00:08:07 - [fold 1] best test MAP: 0.369 @ epoch 19
00:08:07 - Evaluating every 1 epochs ...
00:08:07 - reading data from /mnt/home/puxuan/CLIR-project/Evaluation_data/process-clef/uncased
00:08:07 - test has 37 queries ...
00:08:07 - Data reading done ...
00:08:09 - adding 9-th encoder to optimizer...
00:08:09 - adding 10-th encoder to optimizer...
00:08:09 - adding 11-th encoder to optimizer...
00:08:09 - process[3]: training epoch 0 ...
00:08:19 - process[3] - epoch 0 - train iter 276 - 21966.1 words/s - loss: 0.6885
00:08:19 - process[3]: training epoch 1 ...
00:08:31 - process[3] - epoch 1 - train iter 276 - 19596.5 words/s - loss: 0.6781
00:08:31 - process[3]: training epoch 2 ...
00:08:42 - process[3] - epoch 2 - train iter 276 - 20986.7 words/s - loss: 0.6708
00:08:42 - process[3]: training epoch 3 ...
00:08:52 - process[3] - epoch 3 - train iter 276 - 21263.3 words/s - loss: 0.6603
00:08:52 - process[3]: training epoch 4 ...
00:09:03 - process[3] - epoch 4 - train iter 276 - 21239.4 words/s - loss: 0.6440
00:09:03 - process[3]: training epoch 5 ...
00:09:14 - process[3] - epoch 5 - train iter 276 - 20695.9 words/s - loss: 0.6397
00:09:14 - process[3]: training epoch 6 ...
00:09:24 - process[3] - epoch 6 - train iter 276 - 21000.2 words/s - loss: 0.6175
00:09:24 - process[3]: training epoch 7 ...
00:09:35 - process[3] - epoch 7 - train iter 276 - 22408.0 words/s - loss: 0.5724
00:09:35 - process[3]: training epoch 8 ...
00:09:45 - process[3] - epoch 8 - train iter 276 - 22198.5 words/s - loss: 0.5712
00:09:45 - process[3]: training epoch 9 ...
00:09:56 - process[3] - epoch 9 - train iter 276 - 21428.2 words/s - loss: 0.5619
00:09:56 - process[3]: training epoch 10 ...
00:10:06 - process[3] - epoch 10 - train iter 276 - 21229.1 words/s - loss: 0.5437
00:10:06 - process[3]: evaluating epoch 10 on dev ...
00:10:31 - dev set during evaluation: 11380/11372
00:10:31 - process[3] - dev - epoch 10 - mAP: 0.303 w/ 37 queries
00:10:31 - process[3]: evaluating epoch 10 on test ...
00:10:49 - process[3] - test - epoch 10 - mAP: 0.288 w/ 37 queries
00:10:49 - process[3]: training epoch 11 ...
00:11:00 - process[3] - epoch 11 - train iter 276 - 20507.9 words/s - loss: 0.5307
00:11:00 - process[3]: evaluating epoch 11 on dev ...
00:11:19 - dev set during evaluation: 11380/11372
00:11:19 - process[3] - dev - epoch 11 - mAP: 0.313 w/ 37 queries
00:11:19 - process[3]: evaluating epoch 11 on test ...
00:11:36 - process[3] - test - epoch 11 - mAP: 0.335 w/ 37 queries
00:11:36 - process[3]: training epoch 12 ...
00:11:47 - process[3] - epoch 12 - train iter 276 - 20379.0 words/s - loss: 0.5154
00:11:47 - process[3]: evaluating epoch 12 on dev ...
00:12:05 - dev set during evaluation: 11380/11372
00:12:05 - process[3] - dev - epoch 12 - mAP: 0.312 w/ 37 queries
00:12:05 - process[3]: training epoch 13 ...
00:12:16 - process[3] - epoch 13 - train iter 276 - 20619.1 words/s - loss: 0.5381
00:12:16 - process[3]: evaluating epoch 13 on dev ...
00:12:35 - dev set during evaluation: 11380/11372
00:12:35 - process[3] - dev - epoch 13 - mAP: 0.336 w/ 37 queries
00:12:35 - process[3]: evaluating epoch 13 on test ...
00:12:52 - process[3] - test - epoch 13 - mAP: 0.317 w/ 37 queries
00:12:52 - process[3]: training epoch 14 ...
00:13:03 - process[3] - epoch 14 - train iter 276 - 20257.1 words/s - loss: 0.5269
00:13:03 - process[3]: evaluating epoch 14 on dev ...
00:13:21 - dev set during evaluation: 11380/11372
00:13:21 - process[3] - dev - epoch 14 - mAP: 0.317 w/ 37 queries
00:13:21 - process[3]: training epoch 15 ...
00:13:32 - process[3] - epoch 15 - train iter 276 - 20283.3 words/s - loss: 0.5035
00:13:32 - process[3]: evaluating epoch 15 on dev ...
00:13:50 - dev set during evaluation: 11380/11372
00:13:50 - process[3] - dev - epoch 15 - mAP: 0.350 w/ 37 queries
00:13:50 - process[3]: evaluating epoch 15 on test ...
00:14:07 - process[3] - test - epoch 15 - mAP: 0.347 w/ 37 queries
00:14:07 - process[3]: training epoch 16 ...
00:14:17 - process[3] - epoch 16 - train iter 276 - 22260.4 words/s - loss: 0.5123
00:14:17 - process[3]: evaluating epoch 16 on dev ...
00:14:37 - dev set during evaluation: 11380/11372
00:14:37 - process[3] - dev - epoch 16 - mAP: 0.321 w/ 37 queries
00:14:37 - process[3]: training epoch 17 ...
00:14:47 - process[3] - epoch 17 - train iter 276 - 21703.0 words/s - loss: 0.5068
00:14:47 - process[3]: evaluating epoch 17 on dev ...
00:15:06 - dev set during evaluation: 11380/11372
00:15:06 - process[3] - dev - epoch 17 - mAP: 0.321 w/ 37 queries
00:15:06 - process[3]: training epoch 18 ...
00:15:17 - process[3] - epoch 18 - train iter 276 - 20461.2 words/s - loss: 0.4904
00:15:17 - process[3]: evaluating epoch 18 on dev ...
00:15:36 - dev set during evaluation: 11380/11372
00:15:36 - process[3] - dev - epoch 18 - mAP: 0.330 w/ 37 queries
00:15:36 - process[3]: training epoch 19 ...
00:15:47 - process[3] - epoch 19 - train iter 276 - 20526.5 words/s - loss: 0.5372
00:15:47 - process[3]: evaluating epoch 19 on dev ...
00:16:06 - dev set during evaluation: 11380/11372
00:16:06 - process[3] - dev - epoch 19 - mAP: 0.341 w/ 37 queries
00:16:06 - [fold 2] best test MAP: 0.347 @ epoch 15
00:16:06 - Evaluating every 1 epochs ...
00:16:06 - reading data from /mnt/home/puxuan/CLIR-project/Evaluation_data/process-clef/uncased
00:16:06 - test has 37 queries ...
00:16:06 - Data reading done ...
00:16:08 - adding 9-th encoder to optimizer...
00:16:08 - adding 10-th encoder to optimizer...
00:16:08 - adding 11-th encoder to optimizer...
00:16:08 - process[3]: training epoch 0 ...
00:16:17 - process[3] - epoch 0 - train iter 240 - 20961.0 words/s - loss: 0.6920
00:16:17 - process[3]: training epoch 1 ...
00:16:26 - process[3] - epoch 1 - train iter 240 - 21197.6 words/s - loss: 0.6851
00:16:26 - process[3]: training epoch 2 ...
00:16:35 - process[3] - epoch 2 - train iter 240 - 21057.8 words/s - loss: 0.6845
00:16:35 - process[3]: training epoch 3 ...
00:16:44 - process[3] - epoch 3 - train iter 240 - 21748.4 words/s - loss: 0.6773
00:16:44 - process[3]: training epoch 4 ...
00:16:53 - process[3] - epoch 4 - train iter 240 - 20902.1 words/s - loss: 0.6437
00:16:53 - process[3]: training epoch 5 ...
00:17:02 - process[3] - epoch 5 - train iter 240 - 21708.1 words/s - loss: 0.5896
00:17:02 - process[3]: training epoch 6 ...
00:17:11 - process[3] - epoch 6 - train iter 240 - 20859.8 words/s - loss: 0.5930
00:17:11 - process[3]: training epoch 7 ...
00:17:20 - process[3] - epoch 7 - train iter 240 - 20981.4 words/s - loss: 0.5489
00:17:20 - process[3]: training epoch 8 ...
00:17:29 - process[3] - epoch 8 - train iter 240 - 21212.5 words/s - loss: 0.5611
00:17:29 - process[3]: training epoch 9 ...
00:17:38 - process[3] - epoch 9 - train iter 240 - 22387.7 words/s - loss: 0.5590
00:17:38 - process[3]: training epoch 10 ...
00:17:47 - process[3] - epoch 10 - train iter 240 - 21316.9 words/s - loss: 0.5380
00:17:47 - process[3]: evaluating epoch 10 on dev ...
00:18:07 - process[3] - dev - epoch 10 - mAP: 0.330 w/ 37 queries
00:18:07 - process[3]: evaluating epoch 10 on test ...
00:18:26 - test set during evaluation: 11210/11201
00:18:26 - process[3] - test - epoch 10 - mAP: 0.356 w/ 37 queries
00:18:26 - process[3]: training epoch 11 ...
00:18:35 - process[3] - epoch 11 - train iter 240 - 20295.3 words/s - loss: 0.5542
00:18:35 - process[3]: evaluating epoch 11 on dev ...
00:18:52 - process[3] - dev - epoch 11 - mAP: 0.325 w/ 37 queries
00:18:52 - process[3]: training epoch 12 ...
00:19:01 - process[3] - epoch 12 - train iter 240 - 21762.6 words/s - loss: 0.5041
00:19:01 - process[3]: evaluating epoch 12 on dev ...
00:19:18 - process[3] - dev - epoch 12 - mAP: 0.315 w/ 37 queries
00:19:18 - process[3]: training epoch 13 ...
00:19:28 - process[3] - epoch 13 - train iter 240 - 20477.9 words/s - loss: 0.4841
00:19:28 - process[3]: evaluating epoch 13 on dev ...
00:19:44 - process[3] - dev - epoch 13 - mAP: 0.345 w/ 37 queries
00:19:44 - process[3]: evaluating epoch 13 on test ...
00:20:04 - test set during evaluation: 11210/11201
00:20:04 - process[3] - test - epoch 13 - mAP: 0.384 w/ 37 queries
00:20:04 - process[3]: training epoch 14 ...
00:20:14 - process[3] - epoch 14 - train iter 240 - 20667.9 words/s - loss: 0.5147
00:20:14 - process[3]: evaluating epoch 14 on dev ...
00:20:30 - process[3] - dev - epoch 14 - mAP: 0.379 w/ 37 queries
00:20:30 - process[3]: evaluating epoch 14 on test ...
00:20:50 - test set during evaluation: 11210/11201
00:20:50 - process[3] - test - epoch 14 - mAP: 0.377 w/ 37 queries
00:20:50 - process[3]: training epoch 15 ...
00:20:59 - process[3] - epoch 15 - train iter 240 - 20700.5 words/s - loss: 0.4338
00:20:59 - process[3]: evaluating epoch 15 on dev ...
00:21:16 - process[3] - dev - epoch 15 - mAP: 0.372 w/ 37 queries
00:21:16 - process[3]: training epoch 16 ...
00:21:25 - process[3] - epoch 16 - train iter 240 - 22047.1 words/s - loss: 0.5186
00:21:25 - process[3]: evaluating epoch 16 on dev ...
00:21:42 - process[3] - dev - epoch 16 - mAP: 0.391 w/ 37 queries
00:21:42 - process[3]: evaluating epoch 16 on test ...
00:22:03 - test set during evaluation: 11210/11201
00:22:03 - process[3] - test - epoch 16 - mAP: 0.368 w/ 37 queries
00:22:03 - process[3]: training epoch 17 ...
00:22:12 - process[3] - epoch 17 - train iter 240 - 22064.3 words/s - loss: 0.4858
00:22:12 - process[3]: evaluating epoch 17 on dev ...
00:22:30 - process[3] - dev - epoch 17 - mAP: 0.370 w/ 37 queries
00:22:30 - process[3]: training epoch 18 ...
00:22:39 - process[3] - epoch 18 - train iter 240 - 20700.6 words/s - loss: 0.4686
00:22:39 - process[3]: evaluating epoch 18 on dev ...
00:22:58 - process[3] - dev - epoch 18 - mAP: 0.353 w/ 37 queries
00:22:58 - process[3]: training epoch 19 ...
00:23:07 - process[3] - epoch 19 - train iter 240 - 20844.8 words/s - loss: 0.4591
00:23:07 - process[3]: evaluating epoch 19 on dev ...
00:23:25 - process[3] - dev - epoch 19 - mAP: 0.372 w/ 37 queries
00:23:25 - [fold 3] best test MAP: 0.368 @ epoch 16
00:23:25 - Evaluating every 1 epochs ...
00:23:25 - reading data from /mnt/home/puxuan/CLIR-project/Evaluation_data/process-clef/uncased
00:23:25 - test has 37 queries ...
00:23:25 - Data reading done ...
00:23:26 - adding 9-th encoder to optimizer...
00:23:26 - adding 10-th encoder to optimizer...
00:23:26 - adding 11-th encoder to optimizer...
00:23:27 - process[3]: training epoch 0 ...
00:23:35 - process[3] - epoch 0 - train iter 231 - 22193.7 words/s - loss: 0.6913
00:23:35 - process[3]: training epoch 1 ...
00:23:43 - process[3] - epoch 1 - train iter 231 - 22233.5 words/s - loss: 0.6878
00:23:43 - process[3]: training epoch 2 ...
00:23:52 - process[3] - epoch 2 - train iter 231 - 21384.2 words/s - loss: 0.6654
00:23:52 - process[3]: training epoch 3 ...
00:24:00 - process[3] - epoch 3 - train iter 231 - 21803.1 words/s - loss: 0.6639
00:24:00 - process[3]: training epoch 4 ...
00:24:09 - process[3] - epoch 4 - train iter 231 - 21658.0 words/s - loss: 0.6445
00:24:09 - process[3]: training epoch 5 ...
00:24:17 - process[3] - epoch 5 - train iter 231 - 22389.9 words/s - loss: 0.6230
00:24:17 - process[3]: training epoch 6 ...
00:24:25 - process[3] - epoch 6 - train iter 231 - 21203.8 words/s - loss: 0.5930
00:24:25 - process[3]: training epoch 7 ...
00:24:34 - process[3] - epoch 7 - train iter 231 - 20347.7 words/s - loss: 0.5760
00:24:34 - process[3]: training epoch 8 ...
00:24:44 - process[3] - epoch 8 - train iter 231 - 20137.0 words/s - loss: 0.5902
00:24:44 - process[3]: training epoch 9 ...
00:24:52 - process[3] - epoch 9 - train iter 231 - 22222.0 words/s - loss: 0.5335
00:24:52 - process[3]: training epoch 10 ...
00:25:00 - process[3] - epoch 10 - train iter 231 - 21164.1 words/s - loss: 0.5860
00:25:00 - process[3]: evaluating epoch 10 on dev ...
00:25:24 - dev set during evaluation: 11210/11201
00:25:24 - process[3] - dev - epoch 10 - mAP: 0.359 w/ 37 queries
00:25:24 - process[3]: evaluating epoch 10 on test ...
00:25:41 - test set during evaluation: 10640/10633
00:25:41 - process[3] - test - epoch 10 - mAP: 0.326 w/ 37 queries
00:25:41 - process[3]: training epoch 11 ...
00:25:50 - process[3] - epoch 11 - train iter 231 - 21488.4 words/s - loss: 0.5006
00:25:50 - process[3]: evaluating epoch 11 on dev ...
00:26:10 - dev set during evaluation: 11210/11201
00:26:10 - process[3] - dev - epoch 11 - mAP: 0.388 w/ 37 queries
00:26:10 - process[3]: evaluating epoch 11 on test ...
00:26:28 - test set during evaluation: 10640/10633
00:26:28 - process[3] - test - epoch 11 - mAP: 0.356 w/ 37 queries
00:26:28 - process[3]: training epoch 12 ...
00:26:36 - process[3] - epoch 12 - train iter 231 - 21843.2 words/s - loss: 0.4747
00:26:36 - process[3]: evaluating epoch 12 on dev ...
00:26:56 - dev set during evaluation: 11210/11201
00:26:56 - process[3] - dev - epoch 12 - mAP: 0.392 w/ 37 queries
00:26:56 - process[3]: evaluating epoch 12 on test ...
00:27:14 - test set during evaluation: 10640/10633
00:27:14 - process[3] - test - epoch 12 - mAP: 0.367 w/ 37 queries
00:27:14 - process[3]: training epoch 13 ...
00:27:22 - process[3] - epoch 13 - train iter 231 - 22506.0 words/s - loss: 0.5016
00:27:22 - process[3]: evaluating epoch 13 on dev ...
00:27:42 - dev set during evaluation: 11210/11201
00:27:42 - process[3] - dev - epoch 13 - mAP: 0.380 w/ 37 queries
00:27:42 - process[3]: training epoch 14 ...
00:27:51 - process[3] - epoch 14 - train iter 231 - 21258.2 words/s - loss: 0.4968
00:27:51 - process[3]: evaluating epoch 14 on dev ...
00:28:11 - dev set during evaluation: 11210/11201
00:28:11 - process[3] - dev - epoch 14 - mAP: 0.411 w/ 37 queries
00:28:11 - process[3]: evaluating epoch 14 on test ...
00:28:28 - test set during evaluation: 10640/10633
00:28:28 - process[3] - test - epoch 14 - mAP: 0.364 w/ 37 queries
00:28:28 - process[3]: training epoch 15 ...
00:28:37 - process[3] - epoch 15 - train iter 231 - 21259.4 words/s - loss: 0.4643
00:28:37 - process[3]: evaluating epoch 15 on dev ...
00:28:57 - dev set during evaluation: 11210/11201
00:28:57 - process[3] - dev - epoch 15 - mAP: 0.387 w/ 37 queries
00:28:57 - process[3]: training epoch 16 ...
00:29:05 - process[3] - epoch 16 - train iter 231 - 21255.3 words/s - loss: 0.4730
00:29:05 - process[3]: evaluating epoch 16 on dev ...
00:29:25 - dev set during evaluation: 11210/11201
00:29:25 - process[3] - dev - epoch 16 - mAP: 0.381 w/ 37 queries
00:29:25 - process[3]: training epoch 17 ...
00:29:34 - process[3] - epoch 17 - train iter 231 - 21154.0 words/s - loss: 0.4651
00:29:34 - process[3]: evaluating epoch 17 on dev ...
00:29:53 - dev set during evaluation: 11210/11201
00:29:53 - process[3] - dev - epoch 17 - mAP: 0.388 w/ 37 queries
00:29:53 - process[3]: training epoch 18 ...
00:30:01 - process[3] - epoch 18 - train iter 231 - 21483.9 words/s - loss: 0.4237
00:30:01 - process[3]: evaluating epoch 18 on dev ...
00:30:22 - dev set during evaluation: 11210/11201
00:30:22 - process[3] - dev - epoch 18 - mAP: 0.417 w/ 37 queries
00:30:22 - process[3]: evaluating epoch 18 on test ...
00:30:39 - test set during evaluation: 10640/10633
00:30:39 - process[3] - test - epoch 18 - mAP: 0.392 w/ 37 queries
00:30:39 - process[3]: training epoch 19 ...
00:30:47 - process[3] - epoch 19 - train iter 231 - 22808.1 words/s - loss: 0.4776
00:30:47 - process[3]: evaluating epoch 19 on dev ...
00:31:07 - dev set during evaluation: 11210/11201
00:31:07 - process[3] - dev - epoch 19 - mAP: 0.393 w/ 37 queries
00:31:07 - [fold 4] best test MAP: 0.392 @ epoch 18
00:31:07 - Evaluating every 1 epochs ...
00:31:07 - reading data from /mnt/home/puxuan/CLIR-project/Evaluation_data/process-clef/uncased
00:31:08 - test has 37 queries ...
00:31:08 - Data reading done ...
00:31:09 - adding 9-th encoder to optimizer...
00:31:09 - adding 10-th encoder to optimizer...
00:31:09 - adding 11-th encoder to optimizer...
00:31:10 - process[3]: training epoch 0 ...
00:31:19 - process[3] - epoch 0 - train iter 235 - 20699.0 words/s - loss: 0.6869
00:31:19 - process[3]: training epoch 1 ...
00:31:28 - process[3] - epoch 1 - train iter 235 - 20884.8 words/s - loss: 0.6817
00:31:28 - process[3]: training epoch 2 ...
00:31:37 - process[3] - epoch 2 - train iter 235 - 21368.5 words/s - loss: 0.6705
00:31:37 - process[3]: training epoch 3 ...
00:31:46 - process[3] - epoch 3 - train iter 235 - 19831.2 words/s - loss: 0.6555
00:31:46 - process[3]: training epoch 4 ...
00:31:55 - process[3] - epoch 4 - train iter 235 - 21940.3 words/s - loss: 0.6413
00:31:55 - process[3]: training epoch 5 ...
00:32:04 - process[3] - epoch 5 - train iter 235 - 22408.1 words/s - loss: 0.6415
00:32:04 - process[3]: training epoch 6 ...
00:32:13 - process[3] - epoch 6 - train iter 235 - 20489.2 words/s - loss: 0.5809
00:32:13 - process[3]: training epoch 7 ...
00:32:23 - process[3] - epoch 7 - train iter 235 - 20124.9 words/s - loss: 0.5910
00:32:23 - process[3]: training epoch 8 ...
00:32:31 - process[3] - epoch 8 - train iter 235 - 22676.7 words/s - loss: 0.5508
00:32:31 - process[3]: training epoch 9 ...
00:32:41 - process[3] - epoch 9 - train iter 235 - 20257.5 words/s - loss: 0.5379
00:32:41 - process[3]: training epoch 10 ...
00:32:50 - process[3] - epoch 10 - train iter 235 - 20849.7 words/s - loss: 0.5632
00:32:50 - process[3]: evaluating epoch 10 on dev ...
00:33:08 - dev set during evaluation: 10640/10633
00:33:08 - process[3] - dev - epoch 10 - mAP: 0.332 w/ 37 queries
00:33:08 - process[3]: evaluating epoch 10 on test ...
00:33:26 - process[3] - test - epoch 10 - mAP: 0.336 w/ 37 queries
00:33:26 - process[3]: training epoch 11 ...
00:33:36 - process[3] - epoch 11 - train iter 235 - 21100.1 words/s - loss: 0.5299
00:33:36 - process[3]: evaluating epoch 11 on dev ...
00:33:54 - dev set during evaluation: 10640/10633
00:33:54 - process[3] - dev - epoch 11 - mAP: 0.300 w/ 37 queries
00:33:54 - process[3]: training epoch 12 ...
00:34:03 - process[3] - epoch 12 - train iter 235 - 21179.3 words/s - loss: 0.5179
00:34:03 - process[3]: evaluating epoch 12 on dev ...
00:34:20 - dev set during evaluation: 10640/10633
00:34:20 - process[3] - dev - epoch 12 - mAP: 0.317 w/ 37 queries
00:34:20 - process[3]: training epoch 13 ...
00:34:29 - process[3] - epoch 13 - train iter 235 - 21625.1 words/s - loss: 0.5034
00:34:29 - process[3]: evaluating epoch 13 on dev ...
00:34:47 - dev set during evaluation: 10640/10633
00:34:47 - process[3] - dev - epoch 13 - mAP: 0.348 w/ 37 queries
00:34:47 - process[3]: evaluating epoch 13 on test ...
00:35:06 - process[3] - test - epoch 13 - mAP: 0.350 w/ 37 queries
00:35:06 - process[3]: training epoch 14 ...
00:35:14 - process[3] - epoch 14 - train iter 235 - 21921.2 words/s - loss: 0.5131
00:35:14 - process[3]: evaluating epoch 14 on dev ...
00:35:32 - dev set during evaluation: 10640/10633
00:35:32 - process[3] - dev - epoch 14 - mAP: 0.318 w/ 37 queries
00:35:32 - process[3]: training epoch 15 ...
00:35:41 - process[3] - epoch 15 - train iter 235 - 22192.4 words/s - loss: 0.4748
00:35:41 - process[3]: evaluating epoch 15 on dev ...
00:35:59 - dev set during evaluation: 10640/10633
00:35:59 - process[3] - dev - epoch 15 - mAP: 0.303 w/ 37 queries
00:35:59 - process[3]: training epoch 16 ...
00:36:08 - process[3] - epoch 16 - train iter 235 - 21281.8 words/s - loss: 0.5145
00:36:08 - process[3]: evaluating epoch 16 on dev ...
00:36:25 - dev set during evaluation: 10640/10633
00:36:25 - process[3] - dev - epoch 16 - mAP: 0.328 w/ 37 queries
00:36:25 - process[3]: training epoch 17 ...
00:36:34 - process[3] - epoch 17 - train iter 235 - 21783.6 words/s - loss: 0.4625
00:36:34 - process[3]: evaluating epoch 17 on dev ...
00:36:52 - dev set during evaluation: 10640/10633
00:36:52 - process[3] - dev - epoch 17 - mAP: 0.322 w/ 37 queries
00:36:52 - process[3]: training epoch 18 ...
00:37:01 - process[3] - epoch 18 - train iter 235 - 20991.5 words/s - loss: 0.4767
00:37:01 - process[3]: evaluating epoch 18 on dev ...
00:37:19 - dev set during evaluation: 10640/10633
00:37:19 - process[3] - dev - epoch 18 - mAP: 0.323 w/ 37 queries
00:37:19 - process[3]: training epoch 19 ...
00:37:27 - process[3] - epoch 19 - train iter 235 - 22105.8 words/s - loss: 0.4376
00:37:27 - process[3]: evaluating epoch 19 on dev ...
00:37:45 - dev set during evaluation: 10640/10633
00:37:45 - process[3] - dev - epoch 19 - mAP: 0.342 w/ 37 queries
00:37:45 - [fold 5] best test MAP: 0.350 @ epoch 13
00:37:45 - [0.3692824058540838, 0.34683405856558785, 0.36845048563003563, 0.39176968388293576, 0.3503016289847396]
00:37:45 - [37, 37, 37, 37, 37]
00:37:45 - final MAP: 0.365
